{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "461e82ee",
   "metadata": {},
   "source": [
    "# Practical Session: Probabilistic Numerics for ODEs\n",
    "Author: [Nathanael Bosch](https://nathanaelbosch.github.io)\n",
    "\n",
    "\n",
    "## **Overview**\n",
    "\n",
    "In this tutorial you will **implement your own ODE filter, completely from scratch!** \n",
    "The tutorial is structured as follows:\n",
    "\n",
    "0. [**The ODE**](#problem-setting)  \n",
    "   The guiding example for this tutorial will be an epidemeological dynamical system: a so-called SIRD model.\n",
    "   It is a simple model that describes how a disease evolves over time in a population.\n",
    "1. [**Solve an ODE with forward Euler**](#forward-euler)  \n",
    "   The \"hello world\" of solving ODEs. \n",
    "   Forward Euler is a very simple, non-probabilistic ODE solver. \n",
    "   We will use it to perform first simulations of the SIRD model, and we will visualize the solution and the numerical errors - _which are not quantified by the algorithm_.\n",
    "2. _Towards ODE filters:_ [**Gauss-Markov priors and Gaussian inference**](#prior)  \n",
    "   ODE filters essentially perform nonlinear Gauss-Markov regression.\n",
    "   So, in this next step we explore these Gauss-Markov priors and get more familiar with Gaussian distributions.\n",
    "   We  \n",
    "   &nbsp; &nbsp; + [sample from a Gauss--Markov prior](#sampling)  \n",
    "   &nbsp; &nbsp; + implement Gaussian [marginalization](#marginalization) and [conditioning](#affine-conditioning)  \n",
    "   &nbsp; &nbsp; + condition on non-linear observations by [linearizing](#linearization) the model  \n",
    "   These are the main algorithmic building blocks that we need for _extended Kalman filtering_; next, we turn it into an _ODE filter_.\n",
    "3. [**The ODE information operator**](#information-operator)  \n",
    "   In this section we define they key component of the ODE filter: the _information operator_.\n",
    "   This is the part that turns an extended Kalman filter into an ODE solver! \n",
    "4. Putting things together: [**Your first ODE filter**](#ode-filtering)  \n",
    "   We assemble all of the above to build an ODE filter, and we use it to solve the SIRD model.\n",
    "   We will visualize the posterior and its uncertainties, and again look at the numerical error - _and this time also at error estimates_! \n",
    "5. [**Calibrating uncertainties**](#calibration)  \n",
    "   It turns out that there is still one thing left to do: We need to calibrate the error estimates.\n",
    "   So, we implement a quasi-maximum likelihood estimation for the one free _diffusion_ hyperparameter, and get a _calibrated_ ODE filter.\n",
    "   We solve the ODE again, visualize it, and get meaningful posteriors!\n",
    "\n",
    "**At this point you will have implemented your own ODE filter, completely from scratch!**  \n",
    "There is one more section where we use these filters, not to solve an ODE but inside of an inference problem:   \n",
    "\n",
    "6. [**Parameter inference**](#parameter-inference)  \n",
    "   Sometimes you don't want to infer the solution from the ODE, but infer the ODE itself from some data. This is what we'll consider in this _parameter inference_ part.\n",
    "   We will use our ODE filter implementation to do some maximum-likelihood estimation of the SIRD parameters (the contact rate, recovery rate, and death rate).\n",
    "\n",
    "\n",
    "After all of this, if you still have time and are curious for more, there are two directions you could go:\n",
    "there is still quite some functionality that one would want to have when using ODE filters, so you could have a look at [this list](#more) and explore these.\n",
    "Or you could simply check out our [software packages](#software)! They provide feature-rich ODE filters which are implemented very efficiently, and there are many tutorials to guide you through both basic and more avanced use-cases.\n",
    "\n",
    "So without further ado, **let's get started!**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23a5299b",
   "metadata": {},
   "source": [
    "# Preliminaries\n",
    "\n",
    "Make sure you installed all the required packages (see the [requirements.txt](https://github.com/probabilistic-numerics/probnum-spring-school/blob/main/2023_tutorials/requirements.txt)).\n",
    "If not, the following should have you covered:\n",
    "```bash\n",
    "pip3 install --upgrade pip\n",
    "pip3 install numpy matplotlib scipy ipympl\n",
    "pip3 install --upgrade \"jax[cpu]\"\n",
    "```\n",
    "Note that [`jax`](https://github.com/google/jax) can be a bit tricky to install, so in doubt please follow the instructions on [their github page](https://github.com/google/jax#installation).  \n",
    "*Side note:* Always use a [virtual environment](https://docs.python.org/3/tutorial/venv.html)! (or something like [conda](https://docs.conda.io/en/latest/)). \n",
    "\n",
    "The following cell should then run without errors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2541bd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%config InlineBackend.figure_formats = ['svg']\n",
    "%matplotlib inline\n",
    "\n",
    "from typing import Callable, Tuple\n",
    "from functools import partial\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "from scipy.stats import multivariate_normal\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "\n",
    "FIGSIZE = (8, 4)\n",
    "plt.rcParams['figure.figsize'] = FIGSIZE\n",
    "plt.rcParams[\"figure.autolayout\"] = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccdff55f",
   "metadata": {},
   "source": [
    "# 0. Problem Setting: Ordinary Differential Equations (ODEs)  <a class=\"anchor\" id=\"problem-setting\">  </a>\n",
    "\n",
    "_In general_, we are interested to solve ODEs of the form\n",
    "$$\n",
    "\\dot{y}(t) = f(y(t), t), \\quad t \\in [t_0, t_\\text{max}], \\qquad y(t_0) = y_0,\n",
    "$$\n",
    "where $f: \\mathbb{R}^n \\times [t_0, t_\\text{max}] \\to \\mathbb{R}^n$ is the vector field, $[t_0, t_\\text{max}]$ is the time interval, and $y_0 \\in \\mathbb{R}^n$ is the initial condition.  \n",
    "**Our goal is to find $y : [t_0, t_\\text{max}] \\to \\mathbb{R}^n$ which satisfies the ODE and the initial condition. This is what we call the _solution_ of the ODE.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "790b32fd",
   "metadata": {},
   "source": [
    "### The concrete ODE: An epidemeological dynamical system  <a class=\"anchor\" id=\"sird\">  </a>\n",
    "\n",
    "The concrete dynamical system that we will consider in this tutorial is an epidemeological [SIRD model](https://en.wikipedia.org/wiki/Compartmental_models_in_epidemiology#The_SIRD_model), the _Susceptibe-Infectious-Recovered-Deceased model_, which describes the evolution of an infectious disease in a population.\n",
    "It partitions the population into a discrete set of compartments and describes the transitions between these compartments with a set of ordinary differential equations:\n",
    "\n",
    "$$\\begin{aligned}\n",
    "\\frac{dS(t)}{dt} &= -\\beta S(t) I(t) \\\\\n",
    "\\frac{dI(t)}{dt} &= \\beta S(t) I(t) - \\gamma I(t) - \\eta I(t) \\\\\n",
    "\\frac{dR(t)}{dt} &= \\gamma I(t) \\\\\n",
    "\\frac{dD(t)}{dt} &= \\eta I(t)\n",
    "\\end{aligned}$$\n",
    "\n",
    "where $S$, $I$, $R$, and $D$ are the fractions of the population that are susceptible, infected, recovered, and deceased, respectively, \n",
    "and $\\beta$, $\\gamma$, and $\\eta$ are the infection, recovery, and death rates, respectively.\n",
    "In this example, we consider initial conditions $S_0 = 0.99$, $I_0 = 0.01$, $R_0 = 0$, and $D_0 = 0$, parameters $\\beta = 0.5$, $\\gamma = 0.06$, and $\\eta = 0.002$, and a time interval $[t_0, t_\\text{max}] = [0, 100]$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e6be8de",
   "metadata": {},
   "source": [
    "Here is this SIRD problem in code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7387b629",
   "metadata": {},
   "outputs": [],
   "source": [
    "tspan = (0.0, 100.0)\n",
    "y0 = np.array([0.99, 0.01, 0.0, 0.0])\n",
    "p = (beta, gamma, eta) = (0.5, 0.06, 0.002)\n",
    "\n",
    "def f(y, t, p):\n",
    "    S, I, R, D = y\n",
    "    beta, gamma, eta = p\n",
    "    return jnp.array([ \n",
    "        -beta * S * I,\n",
    "        beta * S * I - gamma * I - eta * I,\n",
    "        gamma * I,\n",
    "        eta * I,\n",
    "    ])\n",
    "\n",
    "labels = [\"S(t)\", \"I(t)\", \"R(t)\", \"D(t)\"] # used later for plotting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1ead4d9",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 1. Solve the ODE with forward Euler  <a class=\"anchor\" id=\"forward-euler\">  </a>\n",
    "\n",
    "To warm up and get more familiar with ODEs, let's first solve the ODE with a simple ODE solver, namely [forward Euler](https://en.wikipedia.org/wiki/Euler_method).\n",
    "It works as follows:\n",
    "1. Decide on a discrete time grid $t_0, t_1, \\dots, t_K$. Typically: $t_k = t_0 + k \\Delta t$ for some time step $\\Delta t > 0$.\n",
    "2. Initialize the solution $y(t_0)=y_0$.\n",
    "3. Iteratively compute the solution at the next time step $y(t_{k+1})$ from the solution at the current time step $y(t_k)$:\n",
    "   $$\n",
    "   y(t_{k+1}) = y(t_k) + \\Delta t_k f(y(t_k), t_k).\n",
    "   $$\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "    \n",
    "**Task:** Implement forward Euler in the function `forward_euler` below.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d04aad99",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_euler(f: Callable, y0: np.ndarray, ts: np.ndarray, p=p) -> np.ndarray:\n",
    "    ys = np.zeros((len(ts), len(y0)))\n",
    "\n",
    "    # TODO\n",
    "\n",
    "    return ys"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8153c85",
   "metadata": {},
   "source": [
    "Let's try it out!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b0eea17",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_small = 0.01 \n",
    "times = np.arange(tspan[0], tspan[1], dt_small) \n",
    "ys = forward_euler(f, y0, times)\n",
    "\n",
    "# Plot the result:\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(times, ys, label=labels)\n",
    "ax.set_xlabel(\"t\")\n",
    "ax.set_ylabel(\"y(t)\")\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09ba79f1",
   "metadata": {},
   "source": [
    "Looks good! But we also took very small steps here. What about coarser steps? Or _much_ coarser steps?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddb9beea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n",
    "dt_coarse = \n",
    "times_coarse = \n",
    "ys_coarse = \n",
    "\n",
    "# Plot the result:\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(times, ys, color=\"black\", linestyle=\"--\")\n",
    "ax.plot(times_coarse, ys_coarse, label=labels, marker=\"o\", markersize=3)\n",
    "ax.set_xlabel(\"t\")\n",
    "ax.set_ylabel(\"y(t)\")\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef8b5e5a",
   "metadata": {},
   "source": [
    "We can definitely see the error now. Note that the black dashed \"accurate\" solution also has error of course: it too has been computed by a numerical algorithm. \n",
    "For this notebook, we consider that error to be \"small enough\" so that we can compare the coarser versions to it.\n",
    "\n",
    "Let's directly plot the errors to get an even clearer picture:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d85b23a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For the plot to work, make sure that dt_coarse is a multiple of dt_small\n",
    "print(f\"Make sure that this here is an integer: {dt_coarse / dt_small}\")\n",
    "stride = int(dt_coarse / dt_small)\n",
    "errors = ys_coarse - ys[::stride]\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.axhline(0, color=\"black\", linestyle=\"--\")\n",
    "ax.plot(times_coarse, errors, label=labels, marker=\"o\", markersize=3)\n",
    "ax.set_xlabel(\"t\")\n",
    "ax.set_ylabel(\"error\")\n",
    "ax.set_xlim(*tspan)\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d828b97",
   "metadata": {},
   "source": [
    "There we have it: _there are errors, but they are not quantified by the algorithm!_ Which is unsurprising of course, it's forward Euler after all.\n",
    "\n",
    "So, let's do better and quantify numerical error. **Let's do _Probabilistic Numerics_!**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e2f8934",
   "metadata": {},
   "source": [
    "# 2. Towards Probabilistic Numerical ODE Solvers  <a class=\"anchor\" id=\"pn\">  </a>\n",
    "\n",
    "Let's forget most of the above and start over. \n",
    "We want to find the ODE solution $y : [t_0, t_\\text{max}] \\to \\mathbb{R}^n$ which satisfies the ODE $y'(t) = f(y(t), t)$ and the initial condition $y(t_0) = y_0$.\n",
    "But we also know that, even though there is a unique function $y$ with this property, we can never compute it exactly; we can only compute it _approximately_.\n",
    "So, let's instead find a _probability distribution_ over the ODE solution:\n",
    "$$\n",
    "p \\left( y(t) \\mid y(0) = y_0, \\{ y'(t_i) = f(y(t_i), t_i) \\}_{i=1}^N \\right),\n",
    "$$\n",
    "where $t_0, t_1, \\dots, t_N$ is a discrete time grid. \n",
    "\n",
    "As you probably know from the lectures, we consider this to be a [Bayesian state estimation problem](https://en.wikipedia.org/wiki/Recursive_Bayesian_estimation), which can be solved (approximately) with [extended Kalman filtering](https://en.wikipedia.org/wiki/Extended_Kalman_filter).\n",
    "The result is a _probabilistic numerical ODE solution_, and we call the algorithm an _ODE filter_.\n",
    "\n",
    "**Let's build an ODE filter, step by step!**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66893836",
   "metadata": {},
   "source": [
    "## 2.1. The Gauss--Markov Prior: 2-times integrated Wiener processes <a class=\"anchor\" id=\"prior\"> </a>\n",
    "\n",
    "To do Bayesian inference, we need a prior distribution $p(y(t))$ over the ODE solution $y(t)$.\n",
    "A natural and common choice are $q$-times integrated Wiener processes (with $q \\geq 1$), which are Gauss-Markov processes with transition densities of the form\n",
    "$$\n",
    "p( Y(t+h) \\mid Y(t) ) = \\mathcal{N} \\left( Y(t + h); Y(t) A(h), Q(h) \\right),\n",
    "$$\n",
    "where $A(h)$ and $Q(h)$ are known matrices that depend on the time step $h$ (they will be given in code below).\n",
    "The capital $Y(t)$ is a state vector of dimension $d \\cdot (q+1)$ (where $d$ is the dimension of the ODE) which tracks not just the ODE solution $y(t)$, but also its first $q$ derivatives:\n",
    "$$\n",
    "Y(t) = \\begin{bmatrix} y(t) \\\\ y'(t) \\\\ \\vdots \\\\ y^{(q)}(t) \\end{bmatrix}.\n",
    "$$\n",
    "We can access them via projection matrices $E_0, E_1, \\dots, E_q$: $E_i Y(t) = y^{(i)}(t)$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "536b0473",
   "metadata": {},
   "source": [
    "In code, these are the transition martices of the one-dimensional two-times integrated Wiener process prior:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ce30a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "q = 2\n",
    "def A1(h: float):\n",
    "    return np.array([[1, h, h**2 / 2], [0, 1, h], [0, 0, 1]])\n",
    "\n",
    "sigma_sq = 1e-1 # ignore this hyperparemeter for now; it will be discussed later!\n",
    "def Q1(h: float, sigma_sq=sigma_sq):\n",
    "    return sigma_sq * np.array(\n",
    "    [[h**5 / 20, h**4 / 8, h**3 / 6],\n",
    "     [h**4 / 8, h**3 / 3, h**2 / 2],\n",
    "     [h**3 / 6, h**2 / 2, h]]\n",
    ")\n",
    "\n",
    "A1(0.1), Q1(0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60c1d69c",
   "metadata": {},
   "source": [
    "Since the ODE is $d$-dimensional we also need a $d$-dimensional prior. We can simply use the same prior for each dimension, and then stack them together:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaac270e",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = len(y0)\n",
    "A = lambda h: np.kron(A1(h), np.eye(d))\n",
    "Q = lambda h, sigma_sq=sigma_sq: np.kron(Q1(h, sigma_sq), np.eye(d))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4603ca27",
   "metadata": {},
   "source": [
    "Let's also implement the projection matrices $E_0, E_1, E_2$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75e5eabe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accessing the i-th derivative with E_i\n",
    "E0 = np.kron(np.array([[1, 0, 0]]), np.eye(d))\n",
    "E1 = np.kron(np.array([[0, 1, 0]]), np.eye(d))\n",
    "E2 = np.kron(np.array([[0, 0, 1]]), np.eye(d))\n",
    "E0, E1, E2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d34375d8",
   "metadata": {},
   "source": [
    "We also have a standard Gaussian initial distribution $$p(Y(t_0)) = \\mathcal{N}(Y(t_0); m_0, C_0),$$ and we assume $m_0 = 0$ and $C_0 = I$.\n",
    "\n",
    "*Note:* This initial distribution does not relate to the initial condition $y(t_0) = y_0$ of the ODE! It is just a prior. We will condition on the ODE initial condition later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4bdec29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial mean and covariance\n",
    "m0 = np.zeros(d * (q + 1))\n",
    "C0 = np.eye(d * (q + 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f860b91",
   "metadata": {},
   "source": [
    "## 2.2. Visualize the prior: Sampling <a class=\"anchor\" id=\"sampling\"></a>\n",
    "\n",
    "To get a feeling for the prior $Y(t)$, let's sample from it and plot the samples.\n",
    "Recall: The prior is given by\n",
    "$$\\begin{aligned}\n",
    "p(Y(t_0)) &= \\mathcal{N}(Y(t_0); m_0, C_0) \\\\\n",
    "p(Y(t+h) \\mid Y(t)) &= \\mathcal{N} \\left( Y(t + h); A(h)Y(t), Q(h) \\right),\n",
    "\\end{aligned}$$\n",
    "with $m_0, C_0, A(h), Q(h)$ as given above.\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "    <b>Task:</b> Implement the sampling function <code>sample_prior</code> below.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2225001b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_prior(\n",
    "    m0: np.ndarray, \n",
    "    C0: np.ndarray, \n",
    "    ts: np.ndarray,\n",
    "    A: Callable[[float], np.ndarray], \n",
    "    Q: Callable[[float], np.ndarray]\n",
    ") -> np.ndarray:\n",
    "    sample = np.zeros((len(ts), d*(q+1)))\n",
    "    \n",
    "    # TODO\n",
    "        \n",
    "    return sample"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18465262",
   "metadata": {},
   "source": [
    "Here is some helper code to plot the sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea98bc35",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_sample(ts, sample, axes=None, derivative=0):\n",
    "    if axes is None:\n",
    "        _, axes = plt.subplots(d, figsize=(FIGSIZE[0], FIGSIZE[1]/3*d), sharex=True)\n",
    "\n",
    "    E = (E0, E1, E2)[derivative]\n",
    "    Yi = sample @ E.T\n",
    "    \n",
    "    for j in range(d):\n",
    "        axes[j].plot(ts, Yi[:, j], color=f\"C{j}\")\n",
    "        ddt = \"\" if derivative == 0 else f\"$\\\\frac{{d^{derivative}}}{{dt^{derivative}}}$ \"\n",
    "        axes[j].set_ylabel(f\"{ddt}{labels[j]}\")\n",
    "        axes[j].set_xlim(ts[0], ts[-1])\n",
    "    \n",
    "    axes[-1].set_xlabel(\"t\")\n",
    "\n",
    "    fig = axes[0].get_figure()\n",
    "    return fig, axes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14336258",
   "metadata": {},
   "source": [
    "Let's sample and plot the result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "875d9eaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts = np.linspace(tspan[0], tspan[1], 100)\n",
    "Ys = sample_prior(m0, C0, ts, A, Q)\n",
    "\n",
    "fig, axes = plot_sample(ts, Ys)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5009f01",
   "metadata": {},
   "source": [
    "Neat! To get a better feeling for the prior _distribution_, let's plot many samples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2672a6b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts = np.linspace(tspan[0], tspan[1], 100)\n",
    "fig, axes = plot_sample(ts, Ys)\n",
    "for _ in range(10):\n",
    "    Ys = sample_prior(m0, C0, ts, A, Q)\n",
    "    plot_sample(ts, Ys, axes=axes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0c001f8",
   "metadata": {},
   "source": [
    "**This is what the 2-times integrated Wiener process prior looks like!**\n",
    "\n",
    "Here we show the zeroth derivative of the state vector $Y(t)$, so the prior for the ODE solution $y(t)$.\n",
    "The lines look quite different from the ODE solution that we're looking for; but after all it's just a prior. \n",
    "We will relate the prior to the ODE solution later."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f93afc2",
   "metadata": {},
   "source": [
    "To really see why it's called a \"2-times integrated Wiener process\" we can plot the second derivative of the sample (by setting `derivative=2` in the `plot_sample` call):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8c10852",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the second derivative; it should look like a Wiener process (a random walk)\n",
    "ts = np.linspace(tspan[0], tspan[1], 100)\n",
    "fig, axes = plot_sample(ts, Ys, derivative=2)\n",
    "for _ in range(10):\n",
    "    Ys = sample_prior(m0, C0, ts, A, Q)\n",
    "    plot_sample(ts, Ys, axes=axes, derivative=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74c343e7",
   "metadata": {},
   "source": [
    "## 2.3. Towards inference: Marginalizing and conditioning Gaussians <a class=\"anchor\" id=\"towards-filter\"></a>\n",
    "\n",
    "We have a prior $p(Y(t))$. But we want a posterior $p(Y(t) \\mid \\text{data})$. \n",
    "To get there, we need to _marginalize_ and _condition_ Gaussians."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "708e9d05",
   "metadata": {},
   "source": [
    "### Gaussian marginalization <a class=\"anchor\" id=\"marginalization\"></a>\n",
    "\n",
    "Let $x$ be a Gaussian-distributed random variable with \n",
    "$p(x) = \\mathcal{N}(x; m, P)$, \n",
    "and let $y$ be conditionally Gaussian-distributed given $x$, with\n",
    "$p(y \\mid x) = \\mathcal{N}(y; A x + b, C)$.  \n",
    "Then $y$ is also Gaussian-distributed:\n",
    "$$\n",
    "p(y) = \\mathcal{N}(y; A m + b, A P A^\\top + C).\n",
    "$$\n",
    "\n",
    "<font color='gray'><i>FilteringFunFact: In Kalman filtering, this is also known as the \"predict\" step.</i></font> \n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "    <b>Task:</b> Implement this in the function <code>marginalize_gaussian</code> below.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5e603c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def marginalize_gaussian(\n",
    "    m: np.ndarray, \n",
    "    P: np.ndarray, \n",
    "    A: np.ndarray, \n",
    "    b: np.ndarray,\n",
    "    C: np.ndarray,\n",
    ") -> Tuple[np.ndarray, np.ndarray]:\n",
    "    \n",
    "    # TO IMPLEMENT\n",
    "    \n",
    "    return mnew, Pnew"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67c1caea",
   "metadata": {},
   "source": [
    "Let's iteratively apply this to the prior to compute Gaussian marginals $p(Y(t_i)) = \\mathcal{N}(Y(t_i); m_i, P_i)$ for all $i$.\n",
    "\n",
    "<font color='gray'><i>FilteringFunFact: This is basically a Kalman filter without any data.</i></font> \n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "    <b>Task:</b> Implement this in the function <code>compute_marginals</code> below.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a051cacc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_marginals(\n",
    "    m0: np.ndarray, \n",
    "    C0: np.ndarray, \n",
    "    ts: np.ndarray, \n",
    "    A: Callable[[float], np.ndarray], \n",
    "    Q: Callable[[float], np.ndarray]\n",
    ") -> Tuple[np.ndarray, np.ndarray]:\n",
    "    ms = np.zeros((len(ts), d * (q + 1)))\n",
    "    Cs = np.zeros((len(ts), d * (q + 1), d * (q + 1)))\n",
    "    \n",
    "    # TO IMPLEMENT\n",
    "    \n",
    "    return ms, Cs\n",
    "\n",
    "ts = np.linspace(tspan[0], tspan[1], 100)\n",
    "ms, Cs = compute_marginals(m0, C0, ts, A, Q)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f67b6cf7",
   "metadata": {},
   "source": [
    "Here is some helper code to plot the marginals:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b34c7d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_marginals(ts, ms, Cs, derivative=0):\n",
    "    fig, axes = plt.subplots(d, figsize=(FIGSIZE[0], FIGSIZE[1]/3*d), sharex=True)\n",
    "    E = (E0, E1, E2)[derivative]\n",
    "    mi = ms @ E.T\n",
    "    Ci = np.matmul(np.matmul(E, Cs), E.T)\n",
    "    for j in range(d):\n",
    "        axes[j].plot(ts, mi[:, j], color=f\"C{j}\")\n",
    "        axes[j].fill_between(\n",
    "            ts,\n",
    "            mi[:, j] - 2 * Ci[:, j, j],\n",
    "            mi[:, j] + 2 * Ci[:, j, j],\n",
    "            alpha=0.2,\n",
    "            color=f\"C{j}\",\n",
    "        )        \n",
    "        axes[j].set_xlim(ts[0], ts[-1])\n",
    "        axes[j].set_ylabel(labels[j])\n",
    "    axes[0].set_title(f\"Derivative={derivative}\")\n",
    "    return fig, axes\n",
    "\n",
    "\n",
    "fig, ax = plot_marginals(ts, ms, Cs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "012796a0",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "    <b>Check:</b> Zero-mean, ever-increasing variance, and a y-axis in the order of 1e8?\n",
    "    If yes then your marginalization code is probably correct!\n",
    "</div>\n",
    "\n",
    "So now that we know how to interact with the prior, we will work towards _informing_ the prior about the ODE data.\n",
    "This is done by _conditioning_ the prior."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "115f836c",
   "metadata": {},
   "source": [
    "### Affine Gaussian Conditioning <a class=\"anchor\" id=\"affine-conditioning\"></a>\n",
    "\n",
    "Let $x$ be a Gaussian-distributed random variable with\n",
    "$p(x) = \\mathcal{N}(x; m^-, P^-)$,\n",
    "and let $y$ be conditionally Gaussian-distributed given $x$, with\n",
    "$p(y \\mid x) = \\mathcal{N}(y; A x + b, C)$.\n",
    "Then, $x$ is also conditionally Gaussian-distributed given $y$:\n",
    "$$\n",
    "\\begin{aligned}\n",
    "p(x \\mid y) &= \\mathcal{N}(x; m, P) \\\\\n",
    "m &= m^- + P^- A^\\top (A P^- A^\\top + C)^{-1} (y - A m^- - b) \\\\\n",
    "P &= P^- - P^- A^\\top (A P^- A^\\top + C)^{-1} A P^-.\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "<font color='gray'><i>FilteringFunFact: This is also known as the \"update\" step in Kalman filtering.</i></font> \n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "    <b>Task:</b> Implement this in the function <code>condition_gaussian</code> below.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd7f6f1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def condition_gaussian(\n",
    "    m: np.ndarray, \n",
    "    P: np.ndarray, \n",
    "    A: np.ndarray, \n",
    "    b: np.ndarray, \n",
    "    C: np.ndarray, \n",
    "    y: np.ndarray\n",
    ") -> Tuple[np.ndarray, np.ndarray]:\n",
    "   \n",
    "    # TO IMPLEMENT\n",
    "\n",
    "    return mnew, Pnew"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb3aed9c",
   "metadata": {},
   "source": [
    "Let's try it out! \n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "    <b>Task:</b> Update the initial distribution $p(Y(t_0))$ on the initial condition: $y(t_0) = y_0$.\n",
    "</div>\n",
    "\n",
    "<font color='gray'><i>Hint:</i>\n",
    "Recall that $E_0 Y(t) = y(t)$.  \n",
    "</font> \n",
    "<font color='gray'><i>Hint 2:</i>\n",
    "Conditioning on an equation is equivalent to conditioning on a Dirac observation, which again is equivalent to conditioning on a Gaussian observation with zero variance (i.e. $C = 0$).\n",
    "</font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a55f67cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "m, C = condition_gaussian(m0, C0, E0, 0, 0, y0)\n",
    "m, C"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64d4dd06",
   "metadata": {},
   "source": [
    "After doing this, we should now satisfy the initial condition exactly: $\\mathbb{E}[E_0 Y(t_0)] = y_0$ and $\\mathbb{V}[E_0 Y(t_0)] = 0$!  \n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "    <b>Task:</b> Check that this holds: $\\mathbb{E}[E_0 Y(t_0)] = y_0$ and $\\mathbb{V}[E_0 Y(t_0)] = 0$\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90198e3a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c4609caa",
   "metadata": {},
   "source": [
    "Let's look how this affects the prior marginals:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb6f1e99",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts = np.linspace(0, 0.1, 100)\n",
    "ms, Cs = compute_marginals(m, C, ts, A, Q)\n",
    "fig, axes = plot_marginals(ts, ms, Cs)\n",
    "# also plot the initial value:\n",
    "for i in range(d):\n",
    "    axes[i].scatter(0, y0[i], color=f\"C{i}\", marker=\"o\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86d67140",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "    <b>Check:</b> The mean should still be constant, but not zero, and the variance should still increase over time.\n",
    "    In particular, the initial condition should now be satisfied!\n",
    "</div>\n",
    "\n",
    "From the ODE problem we also get derivative information at the initial time $t_0$: \n",
    "$\\dot{y}(t_0) = f(y_0, t_0)$. \n",
    "This is also useful information, so let's condition on this, too!\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "    <b>Task:</b> Condition on the initial derivative: $\\dot{y}(t_0) = f(y_0, t_0)$.\n",
    "</div>\n",
    "\n",
    "<font color='gray'><i>Hint:</i>\n",
    "Recall that $E_1 Y(t) = \\dot{y}(t)$.\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d1d6724",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n",
    "\n",
    "\n",
    "fig, ax = plot_marginals(ts, ms, Cs) # adjust variable names as necessary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9107d05",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "    <b>Check:</b> The mean should now no be constant anymore, but linear!\n",
    "</div>\n",
    "\n",
    "The last missing piece is to condition _on the ODE itself_. \n",
    "And to be able to do that, we need to condition on non-linear observations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da64050e",
   "metadata": {},
   "source": [
    "### Approximate conditioning via linearization <a class=\"anchor\" id=\"linearization\"></a>\n",
    "\n",
    "Let $x$ be a Gaussian-distributed random variable with\n",
    "$p(x) = \\mathcal{N}(x; m^-, C^-)$,\n",
    "and let $y$ be conditionally Gaussian-distributed given $x$, with\n",
    "$p(y \\mid x) = \\mathcal{N}(y; h(x), R)$.\n",
    "*Then, $x$ is **not** conditionally Gaussian-distributed given $y$.*\n",
    "But to still have efficient, albeit approximate, inference, we can linearize the non-linear observation model $h(x)$ and then still do Gaussian inference.\n",
    "\n",
    "*Taylor-approximation:* We linearize the model by doing a Taylor approximation:\n",
    "$$\n",
    "h(x) \\approx h(\\xi) + H(\\xi)^\\top (x - \\xi),\n",
    "$$\n",
    "where $\\xi$ is some linearization point $\\xi$ and $H(\\xi)$ is the Jacobian of $h$ at $\\xi$.\n",
    "\n",
    "Then, given the approximate observation model $p(y \\mid x) \\approx \\mathcal{N}(y; h(\\xi) + H(\\xi)^\\top (x - \\xi), R)$, $x$ is again conditionally Gaussian-distributed given $y$, with the same update formula as above.\n",
    "\n",
    "Typically we choose $\\xi = m^-$, the mean of the prior.\n",
    "\n",
    "<font color='gray'><i>FilteringFunFact: Doing Gaussian conditioning with a linearized observation model, where the linearization point corresponds to the prior mean, corresponds to an \"extended Kalman update\" step.</i></font> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f04b67c",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <b>Task:</b> Implement the <code>linearize</code> function, which takes in a function <code>h</code> and a linearization point <code>xi</code>, and returns the parameters of a function $h_\\xi(x) = A x + b$ that approximates $h(x)$ around $\\xi$.\n",
    "</div>\n",
    "\n",
    "<font color='gray'><i>Hint:</i>\n",
    "Use [`jax.jacfwd`](https://jax.readthedocs.io/en/latest/_autosummary/jax.jacfwd.html) (or `jax.jacobian`, it doesn't really matter for this tutorial).\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ece4497",
   "metadata": {},
   "outputs": [],
   "source": [
    "def linearize(\n",
    "    h: Callable[[np.ndarray], np.ndarray], \n",
    "    xi: np.ndarray\n",
    ") -> Tuple[np.ndarray, np.ndarray]:\n",
    "    \n",
    "    # TODO  \n",
    "\n",
    "    return A, b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "910fe455",
   "metadata": {},
   "source": [
    "Try it out:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c56ee479",
   "metadata": {},
   "outputs": [],
   "source": [
    "h = lambda x: (x+1) ** 2\n",
    "xi = np.array([0.0])\n",
    "H, b = linearize(h, xi)\n",
    "H, b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac6b9b01",
   "metadata": {},
   "source": [
    "We can also visualize what's we're doing here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8a74e57",
   "metadata": {},
   "outputs": [],
   "source": [
    "xs = np.linspace(-2, 2, 100)\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(xs, h(xs), label=\"h(x)\")\n",
    "ax.plot(xs, (H @ xs[None, :] + b).reshape(-1), label=\"h_lin(x)\")\n",
    "ax.plot(xi, h(xi), color=\"C0\", marker=\"x\", zorder=10, markersize=15, markeredgewidth=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b3cf426",
   "metadata": {},
   "source": [
    "Let's now perform approximate conditioning on a non-linear observation!\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "**Task:** \n",
    "Assume $x \\sim \\mathcal{N}(0, 1)$, a conditional $y \\mid x \\sim \\mathcal{N} (y; h(x), 1e-3)$, and data $y = 0$.\n",
    "Compute an approximate $p(x \\mid y) \\approx \\mathcal{N} (m, P)$, by conditioning on the linearized (or actually \"affine-ized\"?) observation model and data.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee6c119b",
   "metadata": {},
   "outputs": [],
   "source": [
    "m_before, C_before = np.zeros(1), np.eye(1)\n",
    "\n",
    "# TODO\n",
    "\n",
    "\n",
    "m_conditioned, C_conditioned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e2315a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to check that you updated in the correct direction:\n",
    "assert h(m_conditioned) < h(m_before)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74461195",
   "metadata": {},
   "source": [
    "## 2.4. The ODE information operator <a class=\"anchor\" id=\"information-operator\"></a>\n",
    "\n",
    "Let's get back to ODEs! \n",
    "From the lectures you probably already know how to construct the _information operator_, but let's briefly recall it nevertheless:\n",
    "We have\n",
    "$$\\dot{y}(t) = f(y(t), t).$$\n",
    "In the language of the chosen two-times integrated Wiener process prior, this is equivalent to\n",
    "$$E_1 Y(t) = f( E_0 Y(t), t),$$\n",
    "or equivalently\n",
    "$$ 0 = E_1 Y(t) - f( E_0 Y(t), t).$$\n",
    "**This is essentially a nonlinear observation model!** Indeed, let $h_i(Y(t_i)) := E_0 Y(t_i) - f(Y(t_i), t_i)$, then $h_i$ is a nonlinear function of the state $Y(t_i)$, and $h_i(Y(t_i)) = 0$ is the observation $i$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed29c468",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <b>Task:</b> \n",
    "    Implement the ODE information operator <code>h</code> at time $t_0$.\n",
    "</div>\n",
    "\n",
    "*Note:* The vector-field $f$ is independent of the time $t$; at this point the dependence on $t$ is just there to make the code more general."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a8fe472",
   "metadata": {},
   "outputs": [],
   "source": [
    "def h(Y):\n",
    "    # TODO\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7b2cb72",
   "metadata": {},
   "source": [
    "With `h` defined we should be able to just condition (approximately) on this nonlinear observation model.\n",
    "So, let's \"condition on the ODE\"!\n",
    "\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "**Task:** Condition the initial distribution `m0, C0` on the ODE information operator `h` at time `t0`.\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce5b86f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Compute `m0_conditioned`, `C0_conditioned`\n",
    "\n",
    "m0_conditioned, C0_conditioned = \n",
    "\n",
    "print(m0_conditioned)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17eaff40",
   "metadata": {},
   "source": [
    "...this is still zero mean?? Did anything go wrong? \n",
    "No! That's because the zero function $y(t) = 0$ actually solves the ODE, too.\n",
    "That is, $f(0, t) = 0$ holds. \n",
    "Therefore the mean did not change - it was already good.\n",
    "\n",
    "If we condition on the initial value first, and then on the ODE, we get a different result:\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "**Task:** Condition the initial distribution `m0, C0` on the initial value `y0`, and then on the ODE information operator `h` at time `t0`.\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f2e4f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n",
    "print(f\"Prior: y(t0)={E0@m0}, y'(t0)={E1@m0}\")\n",
    "\n",
    "m0_conditioned_0, C0_conditioned_0 = \n",
    "print(f\"After conditioning on the initial value: y(t0)={E0@m0_conditioned_0}, y'(t0)={E1@m0_conditioned_0}\")\n",
    "\n",
    "m0_conditioned_1, C0_conditioned_1 = \n",
    "print(f\"After conditioning on the ODE: y(t0)={E0@m0_conditioned_1}, y'(t0)={E1@m0_conditioned_1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d284f140",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "    \n",
    "**Check:** \n",
    "After conditioning on the initial value `y(t0)` should show the correct value, but `y'(t0)` should be zero; \n",
    "after also conditioning on the ODE, `y(t0)` should be the same as before, but `y'(t0)` should be non-zero (in the orders of 1e-5 to 1e-3).\n",
    "    \n",
    "</div>\n",
    "\n",
    "At this point we have all the building blocks to implement the full ODE filtering algorithm:\n",
    "- we have a 2-times integrated Wiener process prior\n",
    "- we know how to _predict_ future values under the prior (via Gaussian marginalization)\n",
    "- we know how to _update_ the distribution, both on linear observations (for the initial value) and (approximately) on non-linear observations (for the ODE)\n",
    "\n",
    "**Let's put it all together!**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2d4a01f",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"ode-filtering\"></a>\n",
    "# 3. The ODE Filter\n",
    "\n",
    "We use everything that we did above and put it together, to build the following algorithm:\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "    \n",
    "**Algorithm**\n",
    "\n",
    "    Input:\n",
    "    - an initial value problem, consisting of \n",
    "      * a vector-field f and \n",
    "      * initial value y0,\n",
    "    - a prior, consisting of \n",
    "      * an initial distribution (m0, C0), \n",
    "      * transition matrices A(h), Q(h), and \n",
    "      * projections to the zeroth and first derivative E0, E1,\n",
    "    - a discrete-time grid ts=${t_i}_{i=1}^N$ chosen by the user, typically as $t_k=t_0+k*dt$ for some time step dt>0.\n",
    "  \n",
    "    Then:\n",
    "    1. Condition the prior on the initial value y0; Condition the prior on the initial derivative $y'(t_0) = f(y0, t_0)$;\n",
    "    2. For each time point $t_i$, $i \\in \\{1, \\dots, N\\}$:\n",
    "       - Extrapolate from $p(Y(t_{i-1})) = N(m_{i-1}, C_{i-1})$ to $p(Y(t_i)) = N(m_i^P, C_i^P)$ using the prior, via Gaussian marginalization\n",
    "       - Condition $Y(t_i)$ on the ODE information operator $h_i$ at time $t_i$, by\n",
    "          1. linearizing the ODE information operator around the prior mean\n",
    "          2. conditioning on the linearized ODE information operator\n",
    "    \n",
    "    Return: the computed marginals $p(Y(t_i)) \\sim \\mathbb{N} (m_i, C_i)$, $i \\in \\{1, \\dots, N\\}$.\n",
    "    \n",
    "</div>\n",
    "    \n",
    "    \n",
    "<div class=\"alert alert-block alert-info\">\n",
    "    \n",
    "**Task:** Implement the algorithm described above in the `ode_filter` function.\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1a1b884",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ode_filter(\n",
    "        f: Callable[[np.ndarray, float], np.ndarray],\n",
    "        y0: np.ndarray,\n",
    "        ts: np.ndarray,\n",
    "        m0: np.ndarray,\n",
    "        C0: np.ndarray,\n",
    "        A: Callable[[float], np.ndarray],\n",
    "        Q: Callable[[float], np.ndarray],\n",
    "        E0: np.ndarray,\n",
    "        E1: np.ndarray,\n",
    "        p=p, # will become relevant later, so do pass it to `f`!\n",
    "    ) -> Tuple[np.ndarray, np.ndarray]:\n",
    "\n",
    "    # Output:\n",
    "    ms = np.zeros((len(ts), d * (q + 1)))\n",
    "    Cs = np.zeros( (len(ts), d * (q + 1), d * (q + 1)))\n",
    "    \n",
    "    # TO IMPLEMENT\n",
    "\n",
    "    return ms, Cs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4eaba49",
   "metadata": {},
   "source": [
    "Let's test it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeac1595",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = 1\n",
    "ts = np.linspace(tspan[0], tspan[1], int((tspan[1] - tspan[0]) / dt))\n",
    "ms, Cs = ode_filter(f, y0, ts, m0, C0, A, Q, E0, E1)\n",
    "\n",
    "# The filter returns marginals, so we plot them with `plot_marginals`\n",
    "fig, axes = plot_marginals(ts, ms, Cs)\n",
    "for j in range(d):\n",
    "    axes[j].plot(times, ys[:, j], color=\"black\", linestyle=\"--\")\n",
    "[ax.set_ylim(-0.1, 1.1) for ax in axes]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13098172",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "    \n",
    "**Check:** \n",
    "The ODE filter posterior mean (colored lines) and the reference solution (black dashed lines) should (visually) coincide,\n",
    "and there should be a visible credible interval around it.\n",
    "    \n",
    "</div>\n",
    "\n",
    "Looks great! The `ode_filter` is able to solve the ODE, and it also returns uncertainties!\n",
    "\n",
    "Let's visualize uncertainties a bit more by looking at the space of errors directly, i.e. $y(t) - \\hat{y}(t)$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1a811d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_pn_errors(ts, ms, Cs, ys_acc):\n",
    "    print(f\"Make sure that this here is an integer: {dt / dt_small}\")\n",
    "    stride = int(dt / dt_small)\n",
    "    errors = ys_acc[::stride] - ms@E0.T\n",
    "\n",
    "    fig, axes = plt.subplots(d, figsize=(FIGSIZE[0], FIGSIZE[1]/3*d), sharex=True)\n",
    "    for j in range(d):\n",
    "        axes[j].plot(ts, np.zeros_like(errors[:, j]), color=f\"C{j}\")\n",
    "        axes[j].fill_between(\n",
    "            ts,\n",
    "            - 3 * np.sqrt(Cs[:, j, j]),\n",
    "            3 * np.sqrt(Cs[:, j, j]),\n",
    "            color=f\"C{j}\",\n",
    "            alpha=0.2,\n",
    "        )\n",
    "        axes[j].plot(ts, errors[:, j], color=\"black\", linestyle=\"--\")\n",
    "        axes[j].set_ylabel(labels[j])\n",
    "        axes[j].set_xlim(ts[0], ts[-1])\n",
    "    return fig, axes\n",
    "\n",
    "fig, axes = plot_pn_errors(ts, ms, Cs, ys)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d970125b",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "    \n",
    "**Check:** \n",
    "The colored and black-dashed lines should both be around zero, and the y-axis should be in the order of 1.\n",
    "    \n",
    "</div>\n",
    "\n",
    "This plot reveals an important issue:\n",
    "*The actual error seems to be much smaller than the posterior uncertainty.*\n",
    "To be a meaningful error estimate, the posterior uncertainty should be *calibrated*, which (among other things also) means that it should have a similar scale as the true error.\n",
    "How do we do this? By estimating the hyperparameter `sigma_sq` that we didn't really talk about yet!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99d0c280",
   "metadata": {},
   "source": [
    "# 4. Calibrating uncertainties <a class=\"anchor\" id=\"calibration\"></a>\n",
    "\n",
    "*There is a hyperparameter $\\sigma^2$ in our choice of 2-times integrated Wiener process prior that we (purposefully) didn't talk about yet.*\n",
    "\n",
    "As our prior, we have\n",
    "$$\\begin{aligned}\n",
    "Y(t_0) &\\sim \\mathcal{N}(0, \\sigma^2 I), \\\\\n",
    "Y(t+h) \\mid Y(t) &\\sim \\mathcal{N}(Y(t); A(h) Y(t), \\sigma^2 Q(h)),\n",
    "\\end{aligned}$$\n",
    "with some scalar hyperparameter $\\sigma^2$, often also called the *diffusion* parameter.\n",
    "\n",
    "So basically, all the covariances that appear in the prior are scaled by some a-priori unknown parameter $\\sigma^2$.  \n",
    "*It is not really surprising that the posterior uncertainty is not calibrated, if there is some (so far) arbitrarily chosen hyperparameter floating around in our model!*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a0d2596",
   "metadata": {},
   "source": [
    "## How to estimate the diffusion $\\sigma^2$ \n",
    "\n",
    "We can estimate the diffusion $\\sigma^2$ by maximizing the likelihood of the observations, \n",
    "where, strictly speaking, \"observations\" here means the ODE information \"$0$\" observed with the obseravtion model \"$h_i$\". \n",
    "We will not go into detail _why_ this is the correct thing to do \n",
    "(for that have a look [[4]](#r1) or [[7]](#r2)),\n",
    "but **this is how it works:**\n",
    "$$\n",
    "\\hat{\\sigma}_\\text{MLE}^2 = \\frac{1}{Nd} \\sum_{i=1}^N (H m_i^P + b)^\\top (H C_i^P H^\\top)^{-1} (H m_i^P + b),\n",
    "$$\n",
    "are the mean and covariance of the distribution _before_ the conditioning at time $t_i$ (in filtering called the \"prediction\" mean and covariance, thus the \"P\").\n",
    "Note that the quantities inside the sum are computed during the Gaussian conditioning anyways, so a good place to compute these terms is inside the Gaussian conditioning function `condition_gaussian`.\n",
    "Then, once we have $\\hat{\\sigma}_\\text{MLE}^2$, just re-scale the covariances:\n",
    "$$ C_i^\\text{cal} =  \\hat{\\sigma}_\\text{MLE}^2 \\cdot C_i. $$\n",
    "That's it!\n",
    "\n",
    "<font color='gray'>\n",
    "    \n",
    "If you're interested in the details and the derivations and proofs to why we do this, \n",
    "have a look at Section 4 of [[4]](#r1) or Section 3 of [[2]](#r2).\n",
    "    \n",
    "</font>\n",
    "\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "    \n",
    "**Task**: Implement a new function `condition_gaussian_cal` that computes not just the conditioned mean and covariance, but also the term inside the sum above.\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "774b2fca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def condition_gaussian_cal(\n",
    "    m: np.ndarray, \n",
    "    P: np.ndarray, \n",
    "    A: np.ndarray, \n",
    "    b: np.ndarray, \n",
    "    C: np.ndarray, \n",
    "    y: np.ndarray\n",
    ") -> Tuple[np.ndarray, np.ndarray]:\n",
    "   \n",
    "    # TO IMPLEMENT\n",
    "\n",
    "    return mnew, Pnew, sigma_sq_increment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb96428a",
   "metadata": {},
   "source": [
    "Let's implement a _calibrated_ ODE filter now!\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "    \n",
    "**Task:** Implement the calibrated ODE filter in the `ode_filter_cal` function.\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c75c91a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ode_filter_cal(\n",
    "        f: Callable[[np.ndarray, float], np.ndarray],\n",
    "        y0: np.ndarray,\n",
    "        ts: np.ndarray,\n",
    "        m0: np.ndarray,\n",
    "        C0: np.ndarray,\n",
    "        A: Callable[[float], np.ndarray],\n",
    "        Q: Callable[[float], np.ndarray],\n",
    "        E0: np.ndarray,\n",
    "        E1: np.ndarray,\n",
    "        p=p,\n",
    ") -> Tuple[np.ndarray, np.ndarray]:\n",
    "    \n",
    "    # Output:\n",
    "    ms = np.zeros((len(ts), d * (q + 1)))\n",
    "    Cs = np.zeros( (len(ts), d * (q + 1), d * (q + 1)))\n",
    "    \n",
    "    # TO IMPLEMENT\n",
    "\n",
    "    return ms, Cs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57b191d9",
   "metadata": {},
   "source": [
    "Let's test it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63b6eacd",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = 1\n",
    "ts = np.linspace(tspan[0], tspan[1], int((tspan[1] - tspan[0]) / dt))\n",
    "ms, Cs = ode_filter_cal(f, y0, ts, m0, C0, A, Q, E0, E1)\n",
    "\n",
    "# The filter returns marginals, so we plot them with `plot_marginals`\n",
    "fig, axes = plot_marginals(ts, ms, Cs)\n",
    "for j in range(d):\n",
    "    axes[j].plot(times, ys[:, j], color=\"black\", linestyle=\"--\")\n",
    "[ax.set_ylim(-0.1, 1.1) for ax in axes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1944870",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = 1\n",
    "ts = np.linspace(tspan[0], tspan[1], int((tspan[1] - tspan[0]) / dt))\n",
    "ms, Cs = ode_filter_cal(f, y0, ts, m0, C0, A, Q, E0, E1)\n",
    "fig, axes = plot_pn_errors(ts, ms, Cs, ys)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfc325d8",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "    \n",
    "**Check:** \n",
    "The colored lines should be exactly zero, but this time both the colored uncertainty estimates and the numerical error (the black lines) should be visibly non-zero.\n",
    "    \n",
    "</div>\n",
    "\n",
    "**It works! We again get relatively small errors, but this time the errors live on the same scale as the error estimate!**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c71eb4f2",
   "metadata": {},
   "source": [
    "# 5. Parameter estimation with ODE filters <a class=\"anchor\" id=\"parameter-inference\"></a>\n",
    "\n",
    "<font color='gray'>\n",
    "\n",
    "*At this point we're done with the main part: We implemented an ODE filter, completely from scratch. Nice!*  \n",
    "*This final section shows how to _use_ the ODE filter in a problem setting that is not purely about _simulating_ and ODE, but about _learning_ the ODE from data.*\n",
    "\n",
    "</font>\n",
    "\n",
    "In many problems of interest we don't actually want to solve a known ODE.\n",
    "Instead, we have some observed data and a hypothesis for how the data was generated, i.e. a model, and we want to learn the parameters of the model that fit the data best.\n",
    "We call this _parameter estimation_, or sometimes also an _inverse problem_.\n",
    "\n",
    "In the case of ODEs, we can formulate the parameter estimation problem as follows:\n",
    "- We have an **initial value problem**\n",
    "  $$\\dot{y}(t) = f(y(t), t, \\theta), \\quad t \\in [t_0, t_\\text{max}], \\qquad y(t_0) = y_0(\\theta),$$\n",
    "  where $\\theta$ is a vector of (unknown) parameters.\n",
    "- We have **observations**\n",
    "  $$u_i = H y(t_i) + \\epsilon_i, \\qquad i \\in \\{1, \\dots, M\\},$$\n",
    "  where $H$ is a linear observation operator, $\\epsilon_i \\sim \\mathcal{N} (0, \\nu^2I)$ is iid. Gaussian noise, and $t_i$ are the observation times.\n",
    "- **We want to estimate the parameters $\\theta$:** For this tutorial we will just compute _maximum-likelihood estimates_\n",
    "  $$\\hat{\\theta} = \\arg\\max_\\theta \\mathcal{L}(\\theta) = \\arg\\max_\\theta \\log p(u_1, \\dots, u_N \\mid \\theta).$$\n",
    "  <font color='gray'>\n",
    "  The method can also be extended to maximum a-posteriori estimates or to full Bayesian inference; in those cases just add a prior and then either optimize or run MCMC, or other (possibly approximate) inference methods. \n",
    "  But in both cases you need to compute the marginal likelihood - this is the main content of this section.\n",
    "  </font>\n",
    "\n",
    "How do we do this in the context of ODE filters? [This paper [10]](#r7) explains how! \n",
    "In a nutshell, we use the ODE filter _posterior_ as a _prior_ for a standard Gaussian process regression problem, and then compute the maximum likelihood estimate of the parameters $\\theta$ by optimizing the log-likelihood.\n",
    "This is what we'll do - in a slightly simplified setting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e9842f6",
   "metadata": {},
   "source": [
    "## The concrete parameter inference problem \n",
    "\n",
    "We still consider the SIRD model as [above](#sird), but with a reduced time-span $t \\in [0, 15]$.  \n",
    "Let $\\beta = 0.5$, $\\gamma = 0.06$, $\\eta = 0.002$ (as above) be the unknown ground truth parameters.  \n",
    "As _data_, we have just a single observation $u = H y(t_\\text{max})$ at the final time point, \n",
    "with $H = \\begin{bmatrix} 0 & 0 & 1 & 0 \\\\ 0 & 0 & 0 & 1 \\end{bmatrix}$, that is, we observe only the last two dimensions of $y$ corresponding to the number of recovered and dead individuals.\n",
    "Our goal is then to estimate the parameters $\\theta = (\\beta, \\gamma, \\eta)$ from this single observation.\n",
    "\n",
    "So on a high level, the question is: *What are the contact rate, the recovery rate, and the death rate, that would explain the observed number of recovered and dead individuals?*\n",
    "\n",
    "Visually, the problem looks like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5103759b",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_true = (0.5, 0.06, 0.002)\n",
    "\n",
    "_tspan = (0, 15)\n",
    "_ts = np.linspace(*_tspan, 20)\n",
    "ms, Cs = ode_filter_cal(f, y0, _ts, m0, C0, A, Q, E0, E1, p=p_true) # where we expliclty pass the true parameters\n",
    "\n",
    "H = np.array([[0, 0, 1, 0], [0, 0, 0, 1]])\n",
    "data = H@E0@ms[-1]\n",
    "\n",
    "fig, axes = plt.subplots(d, figsize=(FIGSIZE[0], FIGSIZE[1]/3*d), sharex=True)\n",
    "for i in range(d):\n",
    "    axes[i].plot(_ts, ms[:, i], color=\"black\", linestyle=\"--\")\n",
    "    if i >= len(data):\n",
    "        axes[i].plot(_ts[-1], data[i-len(data)], marker=\"x\", color=f\"C{i}\", markersize=15, markeredgewidth=3, label=f\"data\")\n",
    "        axes[i].legend(loc=\"upper left\")\n",
    "    axes[i].set_ylabel(labels[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2721a64-58bd-4046-96a9-86c12f666c0b",
   "metadata": {
    "tags": []
   },
   "source": [
    "Our goal is to recover the true solution (the black dashed line) from the observation (the colored cross).\n",
    "\n",
    "To do this via maximum-likelihood estimation, we need two things:\n",
    "1. We need a marginal likelihood function $p(u \\mid \\theta)$, and then\n",
    "2. We maximize this marginal likelihood (or actually minimize the negative marginal log-likelihood) with some optimizer.\n",
    "So let's get to it!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddf18906",
   "metadata": {},
   "source": [
    "## The marginal likelihood\n",
    "When we run an ODE filter, we compute a posterior\n",
    "$$p(y(t_i) \\mid \\theta) = \\mathcal{N} \\left( y(t_i); E_0 m_i, E_0 P_i E_0^\\top \\right), \\qquad i \\in \\{1, \\dots, N\\}.$$\n",
    "In the parameter inference problem, we assume a data likelihood\n",
    "$$p(u \\mid y(t_\\text{max})) = \\mathcal{N}(u; H y(t_\\text{max}), \\sigma^2 I).$$\n",
    "So, using the (approximate) posterior from the ODE filter above, we can compute the (approximate) marginal likelihood:\n",
    "$$\n",
    "p(u \\mid \\theta) \n",
    "= \\int p(u \\mid y(t_\\text{max})) p(y(t_\\text{max}) \\mid \\theta) \\mathrm{d}y(t_\\text{max}) \n",
    "= \\mathcal{N} \\left(u; H E_0 m_N, H E_0 P_N E_0^\\top H^\\top + \\sigma^2 I \\right),\n",
    "$$\n",
    "since both distributions are Gaussian.  \n",
    "\n",
    "**That's it! This is the one formula that we need to implement to compute the marginal likelihood and then do parameter inference with ODE filters.**\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "    \n",
    "**Task**: Implement a negative marginal log-likelihood function `nll` that computes the negative log-likelihood of the observation $u$ given the parameters $\\theta$.\n",
    "    \n",
    "</div>\n",
    "\n",
    "<font color='gray'><i>Hint:</i>\n",
    "Don't forget to project the ODE filter posterior to the solution space with `E0`, and the solution to the data space with `H`.\n",
    "</font>\n",
    "\n",
    "<font color='gray'><i>Hint 2:</i>\n",
    "You can use `scipy.stats.multivariate_normal.logpdf` class to compute the log-likelihood of a multivariate Gaussian.\n",
    "</font>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4899746",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nll(p) -> float:\n",
    "    \n",
    "    # TO IMPLEMENT\n",
    "\n",
    "    return negloglik\n",
    "\n",
    "p0 = np.array((0.3, 0.03, 0.003))\n",
    "nll(p_true), nll(p0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4619a547",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "    \n",
    "**Check:** `nll(p_true)` should be a lower value than `nll(p0)`. Since `p_true` was used to generate the data, its likelihood should be much higher than the likelihood of another arbitrarily chosen parameter!\n",
    "    \n",
    "If both values are the same, you probably did not pass the parameter `p` on to the ODE vector field `f` in your `ode_filter_cal` implementation.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32821d53",
   "metadata": {},
   "source": [
    "## Minimizing the negative log-likelihood\n",
    "\n",
    "There is only one thing left to do: Compute the maximum-likelihood estimate by minimizing `nll`!\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "    \n",
    "**Task**: Starting from `p0`, minimize the negative marginal log-likelihood `nll` with [`scipy.optimize.minimize`](https://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.minimize.html).\n",
    "    \n",
    "</div>\n",
    "\n",
    "<font color='gray'><i>Hint:</i>\n",
    "The \"Nelder-Mead\" method should work reasonably well. Adding bounds (e.g. `bounds=[(0.1, 1.0), (0.01, 0.1), (0.001, 0.01)]`) might help with stability.\n",
    "\n",
    "(also this might take quite a few minutes, ~5min on my computer)\n",
    "</font>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb414851",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: optimize the loss (takes a while)\n",
    "\n",
    "\n",
    "p_opt, nll(p_opt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc6d57f3",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "    \n",
    "**Check:** `nll(p_opt)` should be much lower than `nll(p0)`, otherwise the optimization went completely wrong.\n",
    "    \n",
    "Also: It is quite probable you did not actually recover the true parameters - _this is intended_. We will have a look at the result of the optimization next.\n",
    "    \n",
    "</div>\n",
    "\n",
    "To properly evaluate the quality of the result, let's make another plot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bfa1ecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "ms0, Cs0 = ode_filter_cal(f, y0, _ts, m0, C0, A, Q, E0, E1, p=p0)\n",
    "ms_opt, Cs_opt = ode_filter_cal(f, y0, _ts, m0, C0, A, Q, E0, E1, p=res.x)\n",
    "\n",
    "fig, axes = plt.subplots(d, figsize=(FIGSIZE[0], FIGSIZE[1]/3*d), sharex=True)\n",
    "for i in range(d):\n",
    "    axes[i].plot(_ts, ms[:, i], color=\"black\", linestyle=\"--\", label=\"p_true\")\n",
    "    axes[i].plot(_ts, ms0[:, i], color=f\"C{i}\", linestyle=\"--\", label=\"p0\")\n",
    "    axes[i].plot(_ts, ms_opt[:, i], color=f\"C{i}\", label=\"p_opt\")\n",
    "    if i >= len(data):\n",
    "        axes[i].plot(_ts[-1], data[i-len(data)], marker=\"x\", color=f\"C{i}\", markersize=15, markeredgewidth=3, label=f\"data\")\n",
    "    axes[i].legend(loc=\"upper left\")\n",
    "    axes[i].set_ylabel(labels[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07a7adf6",
   "metadata": {},
   "source": [
    "It worked! At least, kind of? We did recover parameters that explain the data well. \n",
    "But, the inferred parameters are actually quite different from the true parameters and we see a mismatch between the true and the inferred solution, in particular for the number of susceptible and infected individuals.\n",
    "That's because the very limited data we have is not actually sufficient to identify the parameters uniquely - \n",
    "_which is why it would indeed make sense to be more Bayesian about this and compute an actual posterior over the parameters_. \n",
    "So if you have some time left, you might want to try that out!\n",
    "\n",
    "<font color='gray'>\n",
    "Also: If we had a different setup where S and I are observed too, the inferred solution would have been very close to the true solution (you can verify this for yourself by changing `H` above!).\n",
    "</font>\n",
    "\n",
    "\n",
    "\n",
    "**This concludes the tutorial!** Thanks a lot for reading and coding, and for participating in the workshop, I hope you enjoyed it!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bc9c1d7",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Things that we had to leave out <a class=\"anchor\" id=\"more\"></a>\n",
    "\n",
    "We built a functioning ODE filter from scratch, but there are a few things that we had to leave out for the sake of simplicity.\n",
    "The actual algorithms that appear in most of the literature are a bit more involved, and there are many bells and whistles that can be added to make these methods more flexible, more robust and more performant, _which matter a lot when you actually want to use these methods in practice_.\n",
    "Things we didn't cover include:\n",
    "\n",
    "- **Smoothing:**   \n",
    "  The algorithm we implemented above is a _filter_. \n",
    "  The \"posterior\" we computed is essentially\n",
    "  $$ p \\left( y(t_i) \\mid y(0) = y_0, \\{ y'(t_i) = f(y(t_i), t_i) \\}_{j=1}^{i-1} \\right), \\qquad i \\in \\{1, \\dots, N\\}, $$\n",
    "  that is, the posterior of the solution at time $t_i$ only considers the ODE information up to time $t_{i-1}$.\n",
    "  But what we actually described [above](#pn) is a posterior that considers the ODE information _everywhere_.\n",
    "  This is what a _smoother_ does.\n",
    "  Typically, if you are looking at solution strategies, this might be the quantity you are interested in; and if you want _interpolation_ (i.e. computing the solution at arbitrary times), you will also need to smooth.  \n",
    "  To learn more about filtering and smoothing in general have a look at [this book](#r3) [[1]](#r3);\n",
    "  and in the ODE context, the [\"Probabilistic Numerics\" Book](#r0) is a great starting point!\n",
    "- **Other priors:**   \n",
    "  In this tutorial we only considered a two-times integrated Wiener process prior, but depending on your problem you might want higher orders.\n",
    "  Generally speaking, $q$-times integrated Wiener processes are the most popular choice, and all the [software](#software) packages linked below implement them;\n",
    "  but you could also use other Gauss--Markov priors, e.g. $q$-times integrated Ornstein--Uhlenbeck processes, or even more general Markov processes.  \n",
    "  [This paper [5]](#r4) mentions the various priors; or check out the [ProbNumDiffEq.jl documentation](https://docs.sciml.ai/ProbNumDiffEq/stable/priors/) to just use them.\n",
    "- **Square-root implementation & preconditioning**  \n",
    "  It turns out that the standard extended Kalman filtering implementation that we did here can become numerically unstable for high-dimensional problems and/or very small step sizes [[6]](#r5) - _this is a problem that you will actually run into in practice!_\n",
    "  The solution is to use a square-root implementation, together with preconditioning (essentially a change of coordinates in the state space).  \n",
    "  All the software packages linked [below](#software) implement this and provide numerically stable solvers.\n",
    "- **Approximate linearization:**  \n",
    "  The ODE filter we implemented is essentially a _extended Kalman filter_, which is a Gaussian filter combined with a first-order Taylor linearization of the vector field.\n",
    "  There is more you can do:\n",
    "  We can do a zeroth-order Taylor linearization of the vector field to gain some speed (actually a lot of speed; but at the cost of stability and coarser uncertainty quantification) [[9]](#r6);\n",
    "  or we could also do _statistical linearization_ (related to the _unscented_ Kalman filter that you might have heard about) [[2]](#r9) or [[4]](#r1).  \n",
    "  If you want to just use this functionality, have a look at [probdiffeq](https://pnkraemer.github.io/probdiffeq/) which provides a range of linearization strategies, implemented very efficiently.\n",
    "- **Adaptive time-stepping:**  \n",
    "  In practice, we often want to discretize the ODE _adaptively_, to have more steps in regions where the solution is changing rapidly, and fewer steps in regions where the extrapolation is very accurate.\n",
    "  To learn how to do this with ODE filters, have a look at [[3]](#r10) or [[7]](#r2).  \n",
    "  Or again: Just use any one of the [software](#software) packages linked below.\n",
    "- **Better initialization with taylor-mode autodiff:**  \n",
    "  Above, we initialized the ODE filter with the solution and derivative at the first time point - which left the second derivative, _which we do also model_, uncertain.\n",
    "  [This is not ideal [6], but we can do better:](#r5)\n",
    "  The ODE actually contains information about _all_ derivatives of the solution (just apply the chain rule to verify this),\n",
    "  and it turns out that we can efficiently compute these with a computer by using Taylor-mode automatic differentiation!\n",
    "  For more information have a look at [[6]](#r5), \n",
    "  or [the documentation of `jax.experimental.jet`](https://jax.readthedocs.io/en/latest/jax.experimental.jet.html),\n",
    "  or at [TaylorIntegration.jl](https://perezhz.github.io/TaylorIntegration.jl/stable/).  \n",
    "  Or, just use it with any of the [software](#software) packages linked below.\n",
    "- **Flexible information operators:**  \n",
    "  There are many ODE-related problems that do not 100% exactly correspond to the problem setup from [above](#problem-setup), for example higher-order ODEs, dynamical systems with conserved quantities (e.g. often energy, mass, or momentum), or even differential-algebraic equations.\n",
    "  _You can solve these with (O)DE filters too!_ \n",
    "  See [this paper [8]](#r8) for an explanation of how to do this; \n",
    "  and again, just use any of the [software](#software) packages linked below to do this in practice."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16775b98",
   "metadata": {},
   "source": [
    "# Software packages <a class=\"anchor\" id=\"software\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a007471",
   "metadata": {},
   "source": [
    "### [ProbNumDiffEq.jl](https://nathanaelbosch.github.io/ProbNumDiffEq.jl/stable/): *Probabilistic Numerical Differential Equation solvers in Julia*\n",
    "\n",
    "ProbNumDiffEq.jl provides probabilistic numerical ODE solvers to the Julia [DifferentialEquations.jl](https://diffeq.sciml.ai) ecosystem.\n",
    "They are implemented as easy-to-use drop-in replacements to their classic counterparts, aim to be as fast as possible, and provide most of the bells and whistles mentioned [above](#more).\n",
    "Have a look at the [documentation](https://nathanaelbosch.github.io/ProbNumDiffEq.jl/stable/) for more information; or just try them out with the following code snippet:\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "**Example:** Solving the SIRD model as defined in this tutorial with ProbNumDiffEq.jl\n",
    "\n",
    "```julia\n",
    "using ProbNumDiffEq, Plots\n",
    "\n",
    "# Define the ODE problem\n",
    "function f(u, p, t)\n",
    "    S, I, R, D = u\n",
    "    , ,  = p\n",
    "    return [ - * S * I,  * S * I -  * I -  * I,  * I,  * I ]\n",
    "end \n",
    "u0 = [0.99, 0.01, 0.0, 0.0]\n",
    "tspan = (0.0, 100.0)\n",
    "p = [0.5, 0.06, 0.002]\n",
    "prob = ODEProblem(f, u0, tspan, p)\n",
    "\n",
    "# Solve the ODE problem with an ODE filter\n",
    "sol = solve(prob, EK1())\n",
    "\n",
    "# Plot the solution\n",
    "plot(sol)\n",
    "```\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3daf7913",
   "metadata": {},
   "source": [
    "### [probdiffeq](https://pnkraemer.github.io/probdiffeq/): *Probabilistic solvers for differential equations in Jax*\n",
    "\n",
    "ProbDiffEq implements adaptive probabilistic numerical solvers for initial value problems.\n",
    "It inherits automatic differentiation, vectorisation, and GPU capability from JAX, works well with JAX's just-in-time compilation to achieve high performance, and is compatible with other packages from the Jax ecosystem such as [Optax](https://optax.readthedocs.io/en/latest/index.html) or [Blackjax](https://blackjax.readthedocs.io/en/latest/).\n",
    "Have a look at it's documentation [here](https://pnkraemer.github.io/probdiffeq/)!\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "**Example:** Solving the SIRD model as defined in this tutorial with `probdiffeq`\n",
    "\n",
    "```python\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "\n",
    "from probdiffeq import solution_routines, solvers\n",
    "from probdiffeq.implementations import recipes\n",
    "from probdiffeq.strategies import smoothers\n",
    "\n",
    "# Define the ODE problem \n",
    "@jax.jit\n",
    "def vector_field(y, *, t, p):\n",
    "    S, I, R, D = y\n",
    "    , ,  = p\n",
    "    return jnp.array([ - * S * I,  * S * I -  * I -  * I,  * I,  * I ])\n",
    "u0 = jnp.asarray([0.99, 0.01, 0.0, 0.0])\n",
    "t0, t1 = 0.0, 100.0\n",
    "p = jnp.asarray([0.5, 0.06, 0.002])\n",
    "\n",
    "# Solve the ODE problem with an ODE filter\n",
    "implementation = recipes.DenseTS1.from_params(ode_shape=(len(u0),))\n",
    "strategy = smoothers.Smoother(implementation)\n",
    "solver = solvers.MLESolver(strategy)\n",
    "solution = solution_routines.solve_with_python_while_loop(\n",
    "    vector_field, initial_values=(u0,), t0=t0, t1=t1, solver=solver, parameters=p\n",
    ")\n",
    "\n",
    "# Look at the solution\n",
    "print(\"u =\", solution.u)\n",
    "```\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7875563",
   "metadata": {},
   "source": [
    "### [probnum](https://probnum.readthedocs.io/en/latest/index.html): *Probabilistic Numerics in Python*\n",
    "\n",
    "ProbNum is a Python toolkit which provides probabilistic numerical methods not only for ODEs, but for a whole range of numerical problems in linear algebra, optimization, quadrature and differential equations.\n",
    "It also contains quite a large range of methods for Bayesian filtering and smoothing that you can use to build your own probabilistic ODE solvers.\n",
    "To learn more, have a look at its excellent documentation and the many tutorials [here](https://probnum.readthedocs.io/en/latest/index.html).\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "**Example:** Solving the SIRD model as defined in this tutorial with `probnum`\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "from probnum.diffeq import probsolve_ivp\n",
    "\n",
    "# Define the ODE problem\n",
    "p = [0.5, 0.06, 0.002]\n",
    "def f(t, y):\n",
    "    S, I, R, D = y\n",
    "    , ,  = p\n",
    "    return np.array([ - * S * I,  * S * I -  * I -  * I,  * I,  * I ])\n",
    "def Jf(t, y): # define the jacobian manually\n",
    "    S, I, R, D = y\n",
    "    , ,  = p\n",
    "    return np.array([\n",
    "        [- * I, - * S, 0, 0],\n",
    "        [ * I,  * S -  - , -, -],\n",
    "        [0, , 0, 0],\n",
    "        [0, , 0, 0]\n",
    "    ])\n",
    "y0 = np.array([0.99, 0.01, 0.0, 0.0])\n",
    "t0, tmax = 0.0, 100.0\n",
    "\n",
    "# Solve the ODE problem with an ODE filter\n",
    "sol = probsolve_ivp(f, t0, tmax, y0, df=Jf, method=\"ek1\")\n",
    "\n",
    "# Look at the solution\n",
    "print(\"mean: \", sol.states.mean)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "236191b1-4631-4b34-bb27-12e99cd6b516",
   "metadata": {},
   "source": [
    "# References <a class=\"anchor\" id=\"references\"></a>\n",
    "\n",
    "(sorted roughly by date)\n",
    "\n",
    "- <a class=\"anchor\" id=\"r3\">[1]</a> *Bayesian Filtering and Smoothing*, Srkk, 2013 ([link](https://www.cambridge.org/core/books/bayesian-filtering-and-smoothing/C372FB31C5D9A100F8476C1B23721A67))\n",
    "- <a class=\"anchor\" id=\"r9\">[2]</a> *Active Uncertainty Calibration in Bayesian ODE Solvers*, Kersting and Hennig, 2016 ([link](http://auai.org/uai2016/proceedings/papers/163.pdf))\n",
    "- <a class=\"anchor\" id=\"r10\">[3]</a> *A probabilistic model for the numerical solution of initial value problems*, Tiemann (n Schober) et al, 2019 ([link](https://link.springer.com/article/10.1007/s11222-017-9798-7))\n",
    "- <a class=\"anchor\" id=\"r1\">[4]</a> *Probabilistic solutions to ordinary differential equations as nonlinear Bayesian filtering: a new perspective*, Tronarp et al, 2019 ([link](https://link.springer.com/article/10.1007/s11222-019-09900-1))\n",
    "- <a class=\"anchor\" id=\"r4\">[5]</a> *Bayesian ODE solvers: the maximum a posteriori estimate*, Tronarp et al, 2021 ([link](https://link.springer.com/article/10.1007/s11222-021-09993-7))\n",
    "- <a class=\"anchor\" id=\"r5\">[6]</a> *Stable Implementation of Probabilistic ODE Solvers*, Krmer and Hennig, 2020 ([link](https://arxiv.org/abs/2012.10106))\n",
    "- <a class=\"anchor\" id=\"r2\">[7]</a> *Calibrated Adaptive Probabilistic ODE Solvers*, Bosch et al, 2021 ([link](http://proceedings.mlr.press/v130/bosch21a.html))\n",
    "- <a class=\"anchor\" id=\"r8\">[8]</a> *Pick-and-Mix Information Operators for Probabilistic ODE Solvers*, Bosch et al, 2022 ([link](https://proceedings.mlr.press/v151/bosch22a.html))\n",
    "- <a class=\"anchor\" id=\"r6\">[9]</a> *Probabilistic ODE Solutions in Millions of Dimensions*, Krmer et al, 2022 ([link](https://proceedings.mlr.press/v162/kramer22b.html))\n",
    "- <a class=\"anchor\" id=\"r7\">[10]</a> *Fenrir: Physics-Enhanced Regression for Initial Value Problems*, Tronarp et al, 2022 ([link](https://proceedings.mlr.press/v162/tronarp22a.html))\n",
    "\n",
    "Or you can also find a lot of information covering (most of) the topics above in the PN textbook:\n",
    "\n",
    "- <a class=\"anchor\" id=\"r0\"></a> *Probabilistic Numerics*, Hennig et al, 2021 ([link](https://www.probabilistic-numerics.org/textbooks/))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
